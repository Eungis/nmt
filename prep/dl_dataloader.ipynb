{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------------------------------------\n",
    "# Project     : Chameleon - Make KO-EN translator\n",
    "# Created By  : Eungi\n",
    "# Team        : Generative AI - AI Engineer\n",
    "# Created Date: 2023-08-09\n",
    "# Updated Date: 2023-08-09\n",
    "# Purpose     : Make data_loader for dual learning corpus data\n",
    "# version     : 0.0.1\n",
    "# ---------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "from refiner import refine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make src and tgt\n",
    "- use `Vocabulary`, `TranslationDataset`, `DataLoader` to make dataloader\n",
    "- dual learning is quite different from normal translation.\n",
    "- it requires BOS and EOS token at the end of the src."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import repeat\n",
    "from collections import defaultdict\n",
    "import torch\n",
    "\n",
    "\n",
    "class Vocabulary(object):\n",
    "    # pre-defined token idx\n",
    "    PAD, BOS, EOS, UNK = 0, 1, 2, 3\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        min_freq=1,\n",
    "        max_vocab=99999,\n",
    "    ):\n",
    "        # Default Vocabulary\n",
    "        self.itos = {\n",
    "            Vocabulary.PAD: \"<PAD>\",\n",
    "            Vocabulary.BOS: \"<BOS>\",\n",
    "            Vocabulary.EOS: \"<EOS>\",\n",
    "            Vocabulary.UNK: \"<UNK>\",\n",
    "        }\n",
    "        self.stoi = {token: idx for idx, token in self.itos.items()}\n",
    "\n",
    "        self.min_freq = min_freq\n",
    "        self.max_vocab = max_vocab\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.itos)\n",
    "\n",
    "    @staticmethod\n",
    "    def tokenizer(text, delimiter):\n",
    "        return [tok.strip() for tok in text.split(delimiter)]\n",
    "\n",
    "    def build_vocab(self, sents, delimiter):\n",
    "        # bag of words\n",
    "        bow = defaultdict(int)\n",
    "\n",
    "        for sent in sents:\n",
    "            words = self.tokenizer(sent, delimiter=delimiter)\n",
    "            for word in words:\n",
    "                bow[word] += 1\n",
    "\n",
    "        # limit vocab by removing low frequence word\n",
    "        bow = {word: freq for word, freq in bow.items() if freq >= self.min_freq}\n",
    "        bow = sorted(bow.items(), key=lambda x: -x[1])\n",
    "\n",
    "        # limit size of the vocab\n",
    "        bow = dict(bow[: self.max_vocab - len(self.itos)])\n",
    "\n",
    "        # create vocab\n",
    "        start_idx = len(self.itos)\n",
    "\n",
    "        for word in bow.keys():\n",
    "            self.stoi[word] = start_idx\n",
    "            self.itos[start_idx] = word\n",
    "            start_idx += 1\n",
    "\n",
    "        print(\"Number of vocabularies: \", len(self))\n",
    "\n",
    "    def encode(self, text, delimiter):\n",
    "        \"\"\"\n",
    "        Encode text input. Support batch input.\n",
    "        Return list.\n",
    "        \"\"\"\n",
    "\n",
    "        encoded_text = []\n",
    "\n",
    "        if isinstance(text, list):\n",
    "            # |text| = [text1, text2, ...]\n",
    "            tokenized_text = list(map(self.tokenizer, text, repeat(delimiter)))\n",
    "            # |tokenized_text| = [[token1, token2, ...], [token1, token2, ...]]\n",
    "            for tokens in tokenized_text:\n",
    "                encoded_text += [\n",
    "                    [\n",
    "                        self.stoi[token]\n",
    "                        if token in self.stoi.keys()\n",
    "                        else self.stoi[\"<UNK>\"]\n",
    "                        for token in tokens\n",
    "                    ]\n",
    "                ]\n",
    "                # |encoded_text| = [[token_idx1, token_idx2], [token_idx1, token_idx2]]\n",
    "        else:\n",
    "            # |text| = str\n",
    "            tokenized_text = self.tokenizer(text, delimiter=delimiter)\n",
    "            # |tokenized_text| = [token1, token2, ...]\n",
    "            encoded_text += [\n",
    "                self.stoi[token] if token in self.stoi.keys() else self.stoi[\"<UNK>\"]\n",
    "                for token in tokenized_text\n",
    "            ]\n",
    "            # |encoded_text| = [token_idx1, token_idx2, ...]\n",
    "\n",
    "        return encoded_text\n",
    "\n",
    "    def decode(self, indice, delimiter, removed_indice=[BOS, EOS, PAD]):\n",
    "        \"\"\"\n",
    "        Decode indice input. Support batch input.\n",
    "        Return list.\n",
    "        \"\"\"\n",
    "\n",
    "        decoded_indice = []\n",
    "\n",
    "        # check if indice is batch input\n",
    "        if isinstance(indice, torch.Tensor):\n",
    "            is_nested = indice.ndim > 1\n",
    "            indice = indice.tolist()\n",
    "        else:\n",
    "            is_nested = any(isinstance(elm, list) for elm in indice)\n",
    "\n",
    "        if is_nested:\n",
    "            # |indice| = (batch_size, length)\n",
    "            # |indice| = [[idx1, idx2, ...], [idx1, idx2, ...]]\n",
    "            for encoded_text in indice:\n",
    "                decoded = []\n",
    "                for idx in encoded_text:\n",
    "                    if idx in self.itos.keys() and idx not in removed_indice:\n",
    "                        decoded += [self.itos[idx]]\n",
    "                    elif idx in removed_indice:\n",
    "                        continue\n",
    "                    else:\n",
    "                        decoded += [self.itos[Vocabulary.UNK]]\n",
    "\n",
    "                decoded_indice += [delimiter.join(decoded).strip()]\n",
    "\n",
    "        else:\n",
    "            # |indice| = (length, )\n",
    "            # |indice| = [idx1, idx2, ...]\n",
    "            decoded = []\n",
    "            for idx in indice:\n",
    "                if idx in self.itos.keys() and idx not in removed_indice:\n",
    "                    decoded += [self.itos[idx]]\n",
    "                elif idx in removed_indice:\n",
    "                    continue\n",
    "                else:\n",
    "                    decoded += [self.itos[Vocabulary.UNK]]\n",
    "\n",
    "            decoded_indice += [delimiter.join(decoded).strip()]\n",
    "\n",
    "        return decoded_indice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "DATA_ROOT = \"../data/\"\n",
    "\n",
    "train_data = pd.read_pickle(DATA_ROOT + \"chameleon.train.tok.pickle\")\n",
    "valid_data = pd.read_pickle(DATA_ROOT + \"chameleon.valid.tok.pickle\")\n",
    "test_data = pd.read_pickle(DATA_ROOT + \"chameleon.test.tok.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of vocabularies:  53430\n",
      "Number of vocabularies:  30488\n"
     ]
    }
   ],
   "source": [
    "# build vocabulary\n",
    "\n",
    "src_vocab = Vocabulary()\n",
    "src_vocab.build_vocab(train_data[\"tok_ko\"], delimiter=\" \")\n",
    "\n",
    "tgt_vocab = Vocabulary()\n",
    "tgt_vocab.build_vocab(train_data[\"tok_en\"], delimiter=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from types import NoneType\n",
    "from typing import Type, Union, List\n",
    "\n",
    "\n",
    "class TranslationDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        srcs (list): Sources to be used as the input data.\n",
    "            Note. Sources must be tokenized before putting into Dataset.\n",
    "        tgts (list): Targets to be used as the target data.\n",
    "            Note. Targets must be tokenized before putting into Dataset.\n",
    "        min_freq (int): Minimum frequency to be included in the vocabulary. Defaults to 1.\n",
    "        max_vocab (int): Maximum size of vocabulary. Defaults to 99999.\n",
    "        src_delimiter (str): Delimiter to tokenize the srcs and tgts.\n",
    "        src_vocab (Vocabulary): Vocabulary to encode or decode the srcs of the validation_set and test_set.\n",
    "            Defaults to None.\n",
    "        tgt_vocab (Vocabulary): Vocabulary to encode or decode the tgts of the validation_set and test_set.\n",
    "            Defaults to None.\n",
    "        with_text (bool): Whether to include raw text in the output when calling __getitem__ method.\n",
    "            It is used in evaluation and reinforcement learning. Defaults to False.\n",
    "        is_dual (bool): Whether to make dataloader for dual learning.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        srcs: List[str],\n",
    "        tgts: List[str],\n",
    "        min_freq: int = 1,\n",
    "        max_vocab: int = 99999,\n",
    "        src_delimiter: str = \" \",\n",
    "        tgt_delimiter: str = \" \",\n",
    "        src_vocab: Union[Type[Vocabulary], NoneType] = None,\n",
    "        tgt_vocab: Union[Type[Vocabulary], NoneType] = None,\n",
    "        with_text: bool = False,\n",
    "        is_dual: bool = False,\n",
    "    ):\n",
    "        # Originally, srcs and tgts both must have been tokenized using BPE before.\n",
    "        # But in agri translation model, tgts were tokenized with custom tokenization.\n",
    "        # Instead, tgts have to be delimited by tgt_delimiter before.\n",
    "        self.srcs, self.tgts = srcs, tgts\n",
    "        self.src_delimiter, self.tgt_delimiter = src_delimiter, tgt_delimiter\n",
    "\n",
    "        # If with_text is True, not only the encoded_src and encoded_tgt,\n",
    "        # the raw src and tgt text would be returned together when __getitem__ is called.\n",
    "        self.with_text = with_text\n",
    "        self.is_dual = is_dual\n",
    "\n",
    "        # If the Dataset is train_dataset, it has to build its vocabulary.\n",
    "        if src_vocab is None or tgt_vocab is None:\n",
    "            # Initialize vocabulary of sources and targets\n",
    "            self.src_vocab = Vocabulary(min_freq=min_freq, max_vocab=max_vocab)\n",
    "            self.tgt_vocab = Vocabulary(min_freq=min_freq, max_vocab=max_vocab)\n",
    "            # Build vocabulary of sources and targets\n",
    "            self.src_vocab.build_vocab(self.srcs, delimiter=src_delimiter)\n",
    "            self.tgt_vocab.build_vocab(self.tgts, delimiter=tgt_delimiter)\n",
    "        else:\n",
    "            # If the Dataset is validation or test_dateset, it has to use the vocabulary originated from train_dataset.\n",
    "            self.src_vocab = src_vocab\n",
    "            self.tgt_vocab = tgt_vocab\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.srcs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        src, tgt = self.srcs[idx], self.tgts[idx]\n",
    "\n",
    "        # encode src\n",
    "        # In dual learning, src must have BOS and EOS token at the beginning and the end.\n",
    "        encoded_src = self.src_vocab.encode(src, delimiter=self.src_delimiter)\n",
    "        if self.is_dual:\n",
    "            encoded_src.insert(0, Vocabulary.BOS)\n",
    "            encoded_src.append(Vocabulary.EOS)\n",
    "\n",
    "        # In seq2seq structure, tgt must have BOS and EOS token at the beginning and the end.\n",
    "        encoded_tgt = self.tgt_vocab.encode(tgt, delimiter=self.tgt_delimiter)\n",
    "        encoded_tgt.insert(0, Vocabulary.BOS)\n",
    "        encoded_tgt.append(Vocabulary.EOS)\n",
    "\n",
    "        return_value = {\n",
    "            \"src\": torch.tensor(encoded_src),\n",
    "            \"tgt\": torch.tensor(encoded_tgt),\n",
    "        }\n",
    "\n",
    "        # src_txt and tgt_txt would be used in inference and evaluation\n",
    "        if self.with_text:\n",
    "            return_value[\"src_text\"] = src\n",
    "            return_value[\"tgt_text\"] = tgt\n",
    "\n",
    "        return return_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of vocabularies:  53430\n",
      "Number of vocabularies:  30488\n"
     ]
    }
   ],
   "source": [
    "Dataset = TranslationDataset(\n",
    "    srcs=train_data[\"tok_ko\"].tolist(),\n",
    "    tgts=train_data[\"tok_en\"].tolist(),\n",
    "    with_text=True,\n",
    "    is_dual=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1281934"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([    1,   503,   274,    13,    26,    36, 19091,  1853,    42,  1289,\n",
      "         4184,  8279,   476,     7,  1001,    27,  2130,    11,   153,  1050,\n",
      "         4714, 10429, 24748,    11,  4823, 41928,     4,    25,    19,   160,\n",
      "           28, 16770,     6,  4714,    16,   937,     5,  2690,     4,     2])\n",
      "tensor([   1,  643,  684,   48,    5,   27,  295,  445,   16, 6386, 7716,   29,\n",
      "         527,  333,  310,   10, 9418,   17, 1343,   12, 9369,  257,   11,  633,\n",
      "           8,  229, 2766,  119,    5,   37,   10, 1188,    7,   86,  765,   95,\n",
      "         684,   48,    5, 2321,   17, 1343,   12, 9369,    8,  552,  143,    4,\n",
      "         244,    8,  526,  221,    6,    2])\n"
     ]
    }
   ],
   "source": [
    "# Unlike srcs from normal translation, srcs from dual learning\n",
    "# contains BOS and EOS tokens at the end\n",
    "print(Dataset[10000][\"src\"])\n",
    "print(Dataset[10000][\"tgt\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['▁강 ▁시장 은 ▁\" 한 전공 대가 ▁한 ▁지역의 ▁소유 물이 ▁아닌 , ▁광주 와 ▁전남 이 ▁다시 ▁한번 ▁상생 ▁발전할 ▁마중물 이 ▁되길 ▁소망한다 . \" 고 ▁시 · 도민 의 ▁상생 과 ▁협력 을 ▁당부했다 .']\n",
      "['▁Mayor ▁Kang ▁said , ▁\" I ▁hope ▁that ▁KEPCO ▁Tech ▁will ▁once ▁again ▁become ▁a ▁catalyst ▁for ▁co - prosperity ▁development ▁in ▁Gwangju ▁and ▁South ▁Jeolla ▁Province , ▁not ▁a ▁property ▁of ▁one ▁district ,\" ▁Kang ▁said , ▁asking ▁for ▁co - prosperity ▁and ▁cooperation ▁between ▁the ▁city ▁and ▁provincial ▁residents .']\n"
     ]
    }
   ],
   "source": [
    "print(Dataset.src_vocab.decode(Dataset[10000][\"src\"], delimiter=\" \"))\n",
    "print(Dataset.tgt_vocab.decode(Dataset[10000][\"tgt\"], delimiter=\" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate batch manually\n",
    "import random\n",
    "\n",
    "\n",
    "def generate_batch(batch_size, Dataset):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        batch_size (int): batch_size to load\n",
    "        Dataset (torch.utils.data.Dataset): Dataset generated from pytorch function\n",
    "    \"\"\"\n",
    "    start_idx, n_data = 0, len(Dataset)\n",
    "    indices = list(range(n_data))\n",
    "    random.shuffle(indices)\n",
    "\n",
    "    while True:\n",
    "        batch_indices = indices[start_idx : start_idx + batch_size]\n",
    "        batch = [Dataset[idx] for idx in batch_indices]\n",
    "\n",
    "        if start_idx < n_data:\n",
    "            yield batch\n",
    "            start_idx += batch_size\n",
    "        else:\n",
    "            break\n",
    "\n",
    "\n",
    "# batch_size = 100000\n",
    "# div, mod = divmod(len(Dataset), batch_size)\n",
    "\n",
    "# # n_batchs = 0\n",
    "# # for batch in generate_batch(batch_size, Dataset):\n",
    "# #     n_batchs += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 2\n",
    "batch = next(generate_batch(batch_size, Dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'src': tensor([    1,   131,  1387, 20943, 32592, 37383,  7567,     5,    68,   131,\n",
      "            5,   849,  8777,    28,    16,   347,    34, 10024, 36397,     4,\n",
      "            2]),\n",
      "  'src_text': '▁서울 외 곽 순환도로 ▁평촌 IC 을 ▁통해 ▁서울 을 ▁비롯해 ▁안양 · 과 천 ▁등 ▁접근이 ▁편하다 .',\n",
      "  'tgt': tensor([    1,    87, 23919, 15711,  2761,    13,  3115,     9,  1953,  4911,\n",
      "            8,  6044,    21,   161,    21,    87,    97, 19890,  7510,     6,\n",
      "            2]),\n",
      "  'tgt_text': '▁Seoul ▁Outer ▁Ring ▁Road ▁is ▁convenient ▁to ▁access ▁Anyang '\n",
      "              '▁and ▁Gwacheon ▁as ▁well ▁as ▁Seoul ▁through ▁Pyeongchon ▁IC .'},\n",
      " {'src': tensor([    1, 10481,   338,  3407,  2486,  1530,   358,  1731,     4,     2]),\n",
      "  'src_text': '▁미안하지만 ▁난 ▁필리핀 ▁문화를 ▁이해 ▁못 하겠습니다 .',\n",
      "  'tgt': tensor([    1,  5121,     5,    41,    20,   242,    15,    57,  1009,     4,\n",
      "        12501,   378,     6,     2]),\n",
      "  'tgt_text': \"▁Sorry , ▁but ▁I ▁don ' t ▁understand ▁the ▁Filipino ▁culture \"\n",
      "              '.'}]\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter()\n",
    "pp.pprint(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "\n",
    "class TranslationCollator:\n",
    "    def __init__(\n",
    "        self,\n",
    "        pad_idx: int,\n",
    "        eos_idx: int,\n",
    "        max_length: int,\n",
    "        with_text: bool = False,\n",
    "        is_dual: bool = False,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Usages:\n",
    "            It is used as a parameter in DataLoader.\n",
    "            Collate batch srcs or tgts and process it to make batch loader.\n",
    "            Add length of each src and tgt, and add pad token according to the length of batch.\n",
    "        Args:\n",
    "            pad_idx (int): Index of pad_token.\n",
    "            eos_idx (int): Index of eos_token.\n",
    "            max_length (list): Max length of the encoded_srcs or encoded_tgts .\n",
    "            with_text (bool): Whether to include raw text in the output.\n",
    "            is_dual (bool): Whether it is dual learning or not.\n",
    "        \"\"\"\n",
    "        self.pad_idx = pad_idx\n",
    "        self.eos_idx = eos_idx\n",
    "        self.max_length = max_length\n",
    "        self.with_text = with_text\n",
    "        self.is_dual = is_dual\n",
    "\n",
    "    def truncate_sample(self, sample):\n",
    "        src, tgt = sample[\"src\"][: self.max_length], sample[\"tgt\"][: self.max_length]\n",
    "        if self.is_dual:\n",
    "            if src[-1] != self.eos_idx:\n",
    "                src[-1] = self.eos_idx\n",
    "\n",
    "        if tgt[-1] != self.eos_idx:\n",
    "            tgt[-1] = self.eos_idx\n",
    "        return src, tgt\n",
    "\n",
    "    def __call__(self, batch):\n",
    "        # |batch| = [{\"src\": tensor[], \"tgt\": tensor[]}, {\"src\": tensor[], \"tgt\": tensor[]}...]\n",
    "\n",
    "        srcs, tgts = [], []\n",
    "\n",
    "        # If there are raw text passed from batch, include them in the returned value\n",
    "        # If length of src or target is larger than max_length, truncate it.\n",
    "        # Be careful not to exclude EOS token when truncating the sentence.\n",
    "        if self.with_text:\n",
    "            srcs_texts, tgts_texts = [], []\n",
    "\n",
    "            for sample in batch:\n",
    "                src, tgt = self.truncate_sample(sample)\n",
    "                srcs.append((src, len(src)))\n",
    "                tgts.append((tgt, len(tgt)))\n",
    "\n",
    "                srcs_texts.append(\n",
    "                    \" \".join(sample[\"src_text\"].split(\" \")[: self.max_length - 2])\n",
    "                )\n",
    "                tgts_texts.append(\n",
    "                    \" \".join(sample[\"tgt_text\"].split(\" \")[: self.max_length - 2])\n",
    "                )\n",
    "\n",
    "        else:\n",
    "            for sample in batch:\n",
    "                src, tgt = self.truncate_sample(sample)\n",
    "                srcs.append((src, len(src)))\n",
    "                tgts.append((tgt, len(tgt)))\n",
    "\n",
    "        # |srcs| = [(src_ids, src_length), (src_ids, src_length) ...]\n",
    "        # |srcs_texts| = [src_text, src_text, ...]\n",
    "\n",
    "        # Pad Sequence with pad token according to the length\n",
    "        srcs, srcs_lengths = zip(*srcs)\n",
    "        tgts, tgts_lengths = zip(*tgts)\n",
    "        # |srcs| = [[src_ids], [src_ids] ...]\n",
    "        # |srcs_lenghts| = [src_length, src_length]\n",
    "\n",
    "        srcs = pad_sequence(srcs, batch_first=True, padding_value=self.pad_idx)\n",
    "        tgts = pad_sequence(tgts, batch_first=True, padding_value=self.pad_idx)\n",
    "        # |srcs| = (batch_size, batch_max_length)\n",
    "\n",
    "        srcs = (srcs, torch.LongTensor(srcs_lengths))\n",
    "        tgts = (tgts, torch.LongTensor(tgts_lengths))\n",
    "\n",
    "        return_value = {\n",
    "            \"input_ids\": srcs,\n",
    "            \"output_ids\": tgts,\n",
    "        }\n",
    "\n",
    "        if self.with_text:\n",
    "            return_value[\"input_texts\"] = srcs_texts\n",
    "            return_value[\"output_texts\"] = tgts_texts\n",
    "\n",
    "        return return_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "collator = TranslationCollator(\n",
    "    pad_idx=Vocabulary.PAD,\n",
    "    eos_idx=Vocabulary.EOS,\n",
    "    max_length=5,\n",
    "    with_text=True,\n",
    "    is_dual=True,\n",
    ")\n",
    "\n",
    "model_input_batch = collator(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': (tensor([[    1,   131,  1387, 20943,     2],\n",
       "          [    1, 10481,   338,  3407,     2]]),\n",
       "  tensor([5, 5])),\n",
       " 'output_ids': (tensor([[    1,    87, 23919, 15711,     2],\n",
       "          [    1,  5121,     5,    41,     2]]),\n",
       "  tensor([5, 5])),\n",
       " 'input_texts': ['▁서울 외 곽', '▁미안하지만 ▁난 ▁필리핀'],\n",
       " 'output_texts': ['▁Seoul ▁Outer ▁Ring', '▁Sorry , ▁but']}"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_input_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['▁서울 외 곽', '▁미안하지만 ▁난 ▁필리핀']"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Dataset.src_vocab.decode(model_input_batch[\"input_ids\"][0], delimiter=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of vocabularies:  53430\n",
      "Number of vocabularies:  30488\n"
     ]
    }
   ],
   "source": [
    "train_loader = DataLoader(\n",
    "    TranslationDataset(\n",
    "        srcs=train_data[\"tok_ko\"].tolist(),\n",
    "        tgts=train_data[\"tok_en\"].tolist(),\n",
    "        with_text=True,\n",
    "        is_dual=True,\n",
    "    ),\n",
    "    batch_size=2,\n",
    "    shuffle=True,\n",
    "    collate_fn=TranslationCollator(\n",
    "        pad_idx=Vocabulary.PAD,\n",
    "        eos_idx=Vocabulary.EOS,\n",
    "        max_length=5,\n",
    "        with_text=True,\n",
    "        is_dual=True,\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "mini_batch = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': (tensor([[   1,   44, 1238,  942,    2],\n",
       "          [   1, 1138, 6481,   10,    2]]),\n",
       "  tensor([5, 5])),\n",
       " 'output_ids': (tensor([[   1, 4114,  103,  144,    2],\n",
       "          [   1,   19, 1029,  408,    2]]),\n",
       "  tensor([5, 5])),\n",
       " 'input_texts': ['▁그 ▁밖에 ▁구청장이', '▁인사 부서 는'],\n",
       " 'output_texts': ['▁Any ▁other ▁company', '▁The ▁personnel ▁department']}"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mini_batch"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
